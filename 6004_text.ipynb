{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "crWx0vbNBEz1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/morninlab/Desktop/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from transformers import BertTokenizer, BertModel\n",
        "import logging\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4r9tqAv2CbDT"
      },
      "source": [
        "## Loding data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "6IrBt4h8_pVe",
        "outputId": "965792f6-166f-433c-9b55-fb5aa91a1990"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "shape of the notes file: (81206, 2)\n",
            "unique number of subjects: 20414\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>25696644</td>\n",
              "      <td>HISTORY:  Altered mental status.\\n\\nTECHNIQUE:...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>26048429</td>\n",
              "      <td>INDICATION:  Esophageal carcinoma, status post...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>26048429</td>\n",
              "      <td>HISTORY:  Postop day one interval change.\\n\\nC...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>20214994</td>\n",
              "      <td>EXAMINATION:  CHEST (PRE-OP PA AND LAT)\\n\\nIND...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>20214994</td>\n",
              "      <td>EXAMINATION:  ABDOMINAL RADIOGRAPHS\\n\\nINDICAT...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         id                                               text\n",
              "0  25696644  HISTORY:  Altered mental status.\\n\\nTECHNIQUE:...\n",
              "1  26048429  INDICATION:  Esophageal carcinoma, status post...\n",
              "2  26048429  HISTORY:  Postop day one interval change.\\n\\nC...\n",
              "3  20214994  EXAMINATION:  CHEST (PRE-OP PA AND LAT)\\n\\nIND...\n",
              "4  20214994  EXAMINATION:  ABDOMINAL RADIOGRAPHS\\n\\nINDICAT..."
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "notes = pd.read_csv('notes.csv')[['id', 'text']]\n",
        "print(f'shape of the notes file: {notes.shape}')\n",
        "n_sub = len(pd.unique(notes['id']))\n",
        "print(f'unique number of subjects: {n_sub}')\n",
        "notes.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hkgmBunIw5_T",
        "outputId": "f123bc53-97fd-42a8-957b-5a92c17f300f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "count    20414.000000\n",
              "mean         3.977956\n",
              "std          3.050836\n",
              "min          1.000000\n",
              "25%          2.000000\n",
              "50%          3.000000\n",
              "75%          5.000000\n",
              "max         57.000000\n",
              "Name: count, dtype: float64"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# distribution of how many notes each subject has\n",
        "notes['id'].value_counts().describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "qe6vCe4W7Eyn",
        "outputId": "cd17f8ea-75a1-4ec1-f884-5f33ebc7858f"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>25696644</td>\n",
              "      <td>history:  altered mental status.\\n\\ntechnique:...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>26048429</td>\n",
              "      <td>indication:  esophageal carcinoma, status post...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>26048429</td>\n",
              "      <td>history:  postop day one interval change.\\n\\nc...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>20214994</td>\n",
              "      <td>examination:  chest (pre-op pa and lat)\\n\\nind...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>20214994</td>\n",
              "      <td>examination:  abdominal radiographs\\n\\nindicat...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         id                                               text\n",
              "0  25696644  history:  altered mental status.\\n\\ntechnique:...\n",
              "1  26048429  indication:  esophageal carcinoma, status post...\n",
              "2  26048429  history:  postop day one interval change.\\n\\nc...\n",
              "3  20214994  examination:  chest (pre-op pa and lat)\\n\\nind...\n",
              "4  20214994  examination:  abdominal radiographs\\n\\nindicat..."
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "notes['text'] = notes['text'].str.replace(\"___\", \"\")\n",
        "notes['text'] = notes['text'].str.lower()\n",
        "notes.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### loading essential functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "tFVlraq2CpAV"
      },
      "outputs": [],
      "source": [
        "def token_distribution(df, model_name):\n",
        "  # load tokenizer\n",
        "  tokenizer = BertTokenizer.from_pretrained(model_name)\n",
        "  tokenized = df['text'].apply((lambda x: tokenizer.encode(x, add_special_tokens=True)))\n",
        "\n",
        "  # investigate token\n",
        "  rand_id = random.randint(0, len(tokenized)-1)\n",
        "  print(f'random id: {rand_id}')\n",
        "  print(df['text'][rand_id])\n",
        "  print(tokenizer.convert_ids_to_tokens(tokenized[rand_id]))\n",
        "  print(f'length of the token: {len(tokenized[rand_id])}')\n",
        "\n",
        "\n",
        "  # visualize token distribution\n",
        "  max_len = 0\n",
        "  n = 0\n",
        "  len_ls = tokenized.apply(lambda x: len(x))\n",
        "  for i in tokenized.values:\n",
        "    if len(i) > 512:\n",
        "      n+=1\n",
        "    if len(i) > max_len:\n",
        "        max_len = len(i)\n",
        "  print(f'maximum lenght is {max_len}')\n",
        "  print(f'{n} out of {df.shape[0]} ({n/df.shape[0]*100} %) notes exceed the maximum embedding length of 512')\n",
        "\n",
        "  print(len_ls.describe())\n",
        "  ax = len_ls.plot.box()\n",
        "  plt.axhline(y=512, color='r', linestyle='--')\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "def obtain_batch_embedding(df, model_name):\n",
        "\n",
        "  # load tokenizer\n",
        "  tokenizer = BertTokenizer.from_pretrained(model_name)\n",
        "  tokenizer.truncation_side='left' # truncate from left to preserve more findings\n",
        "\n",
        "  # obtain token id and attention mask\n",
        "  input_ids = []\n",
        "  attention_masks = []\n",
        "  for t in df['text']:\n",
        "    encoded_dict = tokenizer.encode_plus(t,\n",
        "                                        add_special_tokens=True,\n",
        "                                        max_length=512,\n",
        "                                        padding='max_length',\n",
        "                                        return_attention_mask=True,\n",
        "                                        return_tensors='pt',\n",
        "                                        truncation=True)\n",
        "    input_ids.append(encoded_dict['input_ids'].to(device))\n",
        "    attention_masks.append(encoded_dict['attention_mask'].to(device))\n",
        "\n",
        "  # convert to tensor\n",
        "  input_ids = torch.cat(input_ids, dim=0)\n",
        "  attention_masks = torch.cat(attention_masks, dim=0)\n",
        "  print(\"tokens obtained, start fitting model\")\n",
        "\n",
        "  # fit model\n",
        "  model = BertModel.from_pretrained(model_name)\n",
        "  model = model.to(device)\n",
        "  with torch.no_grad():\n",
        "    last_hidden_states = model(input_ids, attention_mask=attention_masks)\n",
        "\n",
        "  features = pd.DataFrame(last_hidden_states[0][:,0,:].cpu().numpy())\n",
        "  features.reset_index(drop=True, inplace=True)\n",
        "  # print(df['id'].shape, features.shape)\n",
        "\n",
        "  # concatenate the id column\n",
        "  res = pd.concat([df['id'].reset_index(drop=True), features], axis=1, ignore_index=True)\n",
        "  print(res.shape)\n",
        "\n",
        "  # take mean value of the embeddings for each individual\n",
        "  # res = features.groupby('id').mean()\n",
        "\n",
        "  return res\n",
        "\n",
        "def embedding(df, model_name, batch_size=256):\n",
        "\n",
        "  # loop through batches\n",
        "  embeddings = pd.DataFrame()\n",
        "  for i in range(0, df.shape[0], batch_size):\n",
        "    print(f'batch from {i}th to {i+batch_size}th sample')\n",
        "    batch = df.iloc[i:i+batch_size]\n",
        "    batch_embedding = obtain_batch_embedding(batch, model_name)\n",
        "    embeddings = pd.concat([embeddings, batch_embedding], axis=0)\n",
        "\n",
        "  return embeddings\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0    25696644\n",
              "1    26048429\n",
              "2    26048429\n",
              "3    20214994\n",
              "4    20214994\n",
              "Name: id, dtype: int64"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "notes['id'].reset_index(drop=True).head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### set up device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'cuda:0'"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
        "device"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### generating embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UbTNPVf3pp0b"
      },
      "outputs": [],
      "source": [
        "# to investigate the distribution of the tokens\n",
        "token_distribution(notes, \"neuml/pubmedbert-base-embeddings\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "512d5b4784e1448bbd51542a5ac76533",
            "09ce4c5e822445098eb77414b27a437c",
            "c7dee6020f174d7eb9b308e75de8430e",
            "ffb540dfc46b4503b9a1bf06368fffa6",
            "2f0be7dc36734becb862adc8c698d4a8",
            "728681d36d404e4ea79c0410f7831f4d",
            "4b78b62a760045e597417f9f0559b8ad",
            "56f710846b8d4351b4f598afea5ebc0b",
            "a847a16f3085463d8000b97e451a59bc",
            "e93c20dfceec45fc9be4723b673e2b64",
            "322f68c193d64c3f92cb352ccdd73278",
            "40dd26682bd44b9d8de3600829967513",
            "2c02f0c35f144c369ae20fbd5760efc4",
            "88780721d2d24779aced35c045e4fc28",
            "2a4ab2707b264a21b7796e4e28bcb1e4",
            "5ecd8a83fc4b48fd8290fe60ec5815b9",
            "f52d6876a46a4cc1b212cf04928581ba",
            "d8710dbf87824f9c9a5488de9c468879",
            "823c739b4a2a482a9515b6a4b90683bd",
            "8f9347d60d1b45b0b9614f27d18d3214",
            "f187031af28543359c9f514a4e6b999b",
            "5b0f8197398f411c88643e2476ad504d"
          ]
        },
        "id": "KiEXnG9iuqO4",
        "outputId": "04af4f6e-4fc8-4aa8-df68-b8a56aad0b21"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "batch from 0th to 256th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 256th to 512th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 512th to 768th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 768th to 1024th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 1024th to 1280th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 1280th to 1536th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 1536th to 1792th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 1792th to 2048th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 2048th to 2304th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 2304th to 2560th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 2560th to 2816th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 2816th to 3072th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 3072th to 3328th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 3328th to 3584th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 3584th to 3840th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 3840th to 4096th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 4096th to 4352th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 4352th to 4608th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 4608th to 4864th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 4864th to 5120th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 5120th to 5376th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 5376th to 5632th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 5632th to 5888th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 5888th to 6144th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 6144th to 6400th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 6400th to 6656th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 6656th to 6912th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 6912th to 7168th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 7168th to 7424th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 7424th to 7680th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 7680th to 7936th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 7936th to 8192th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 8192th to 8448th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 8448th to 8704th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 8704th to 8960th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 8960th to 9216th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 9216th to 9472th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 9472th to 9728th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 9728th to 9984th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 9984th to 10240th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 10240th to 10496th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 10496th to 10752th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 10752th to 11008th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 11008th to 11264th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 11264th to 11520th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 11520th to 11776th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 11776th to 12032th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 12032th to 12288th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 12288th to 12544th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 12544th to 12800th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 12800th to 13056th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 13056th to 13312th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 13312th to 13568th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 13568th to 13824th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 13824th to 14080th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 14080th to 14336th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 14336th to 14592th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 14592th to 14848th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 14848th to 15104th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 15104th to 15360th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 15360th to 15616th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 15616th to 15872th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 15872th to 16128th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 16128th to 16384th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 16384th to 16640th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 16640th to 16896th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 16896th to 17152th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 17152th to 17408th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 17408th to 17664th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 17664th to 17920th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 17920th to 18176th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 18176th to 18432th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 18432th to 18688th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 18688th to 18944th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 18944th to 19200th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 19200th to 19456th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 19456th to 19712th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 19712th to 19968th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 19968th to 20224th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 20224th to 20480th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 20480th to 20736th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 20736th to 20992th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 20992th to 21248th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 21248th to 21504th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 21504th to 21760th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 21760th to 22016th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 22016th to 22272th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 22272th to 22528th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 22528th to 22784th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 22784th to 23040th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 23040th to 23296th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 23296th to 23552th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 23552th to 23808th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 23808th to 24064th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 24064th to 24320th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 24320th to 24576th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 24576th to 24832th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 24832th to 25088th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 25088th to 25344th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 25344th to 25600th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 25600th to 25856th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 25856th to 26112th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 26112th to 26368th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 26368th to 26624th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 26624th to 26880th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 26880th to 27136th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 27136th to 27392th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 27392th to 27648th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 27648th to 27904th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 27904th to 28160th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 28160th to 28416th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 28416th to 28672th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 28672th to 28928th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 28928th to 29184th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 29184th to 29440th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 29440th to 29696th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 29696th to 29952th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 29952th to 30208th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 30208th to 30464th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 30464th to 30720th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 30720th to 30976th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 30976th to 31232th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 31232th to 31488th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 31488th to 31744th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 31744th to 32000th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 32000th to 32256th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 32256th to 32512th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 32512th to 32768th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 32768th to 33024th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 33024th to 33280th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 33280th to 33536th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 33536th to 33792th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 33792th to 34048th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 34048th to 34304th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 34304th to 34560th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 34560th to 34816th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 34816th to 35072th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 35072th to 35328th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 35328th to 35584th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 35584th to 35840th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 35840th to 36096th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 36096th to 36352th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 36352th to 36608th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 36608th to 36864th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 36864th to 37120th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 37120th to 37376th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 37376th to 37632th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 37632th to 37888th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 37888th to 38144th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 38144th to 38400th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 38400th to 38656th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 38656th to 38912th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 38912th to 39168th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 39168th to 39424th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 39424th to 39680th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 39680th to 39936th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 39936th to 40192th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 40192th to 40448th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 40448th to 40704th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 40704th to 40960th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 40960th to 41216th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 41216th to 41472th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 41472th to 41728th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 41728th to 41984th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 41984th to 42240th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 42240th to 42496th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 42496th to 42752th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 42752th to 43008th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 43008th to 43264th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 43264th to 43520th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 43520th to 43776th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 43776th to 44032th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 44032th to 44288th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 44288th to 44544th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 44544th to 44800th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 44800th to 45056th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 45056th to 45312th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 45312th to 45568th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 45568th to 45824th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 45824th to 46080th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 46080th to 46336th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 46336th to 46592th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 46592th to 46848th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 46848th to 47104th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 47104th to 47360th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 47360th to 47616th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 47616th to 47872th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 47872th to 48128th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 48128th to 48384th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 48384th to 48640th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 48640th to 48896th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 48896th to 49152th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 49152th to 49408th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 49408th to 49664th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 49664th to 49920th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 49920th to 50176th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 50176th to 50432th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 50432th to 50688th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 50688th to 50944th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 50944th to 51200th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 51200th to 51456th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 51456th to 51712th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 51712th to 51968th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 51968th to 52224th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 52224th to 52480th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 52480th to 52736th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 52736th to 52992th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 52992th to 53248th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 53248th to 53504th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 53504th to 53760th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 53760th to 54016th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 54016th to 54272th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 54272th to 54528th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 54528th to 54784th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 54784th to 55040th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 55040th to 55296th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 55296th to 55552th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 55552th to 55808th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 55808th to 56064th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 56064th to 56320th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 56320th to 56576th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 56576th to 56832th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 56832th to 57088th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 57088th to 57344th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 57344th to 57600th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 57600th to 57856th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 57856th to 58112th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 58112th to 58368th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 58368th to 58624th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 58624th to 58880th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 58880th to 59136th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 59136th to 59392th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 59392th to 59648th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 59648th to 59904th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 59904th to 60160th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 60160th to 60416th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 60416th to 60672th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 60672th to 60928th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 60928th to 61184th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 61184th to 61440th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 61440th to 61696th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 61696th to 61952th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 61952th to 62208th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 62208th to 62464th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 62464th to 62720th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 62720th to 62976th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 62976th to 63232th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 63232th to 63488th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 63488th to 63744th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 63744th to 64000th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 64000th to 64256th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 64256th to 64512th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 64512th to 64768th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 64768th to 65024th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 65024th to 65280th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 65280th to 65536th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 65536th to 65792th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 65792th to 66048th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 66048th to 66304th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 66304th to 66560th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 66560th to 66816th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 66816th to 67072th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 67072th to 67328th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 67328th to 67584th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 67584th to 67840th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 67840th to 68096th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 68096th to 68352th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 68352th to 68608th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 68608th to 68864th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 68864th to 69120th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 69120th to 69376th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 69376th to 69632th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 69632th to 69888th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 69888th to 70144th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 70144th to 70400th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 70400th to 70656th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 70656th to 70912th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 70912th to 71168th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 71168th to 71424th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 71424th to 71680th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 71680th to 71936th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 71936th to 72192th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 72192th to 72448th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 72448th to 72704th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 72704th to 72960th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 72960th to 73216th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 73216th to 73472th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 73472th to 73728th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 73728th to 73984th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 73984th to 74240th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 74240th to 74496th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 74496th to 74752th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 74752th to 75008th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 75008th to 75264th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 75264th to 75520th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 75520th to 75776th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 75776th to 76032th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 76032th to 76288th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 76288th to 76544th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 76544th to 76800th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 76800th to 77056th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 77056th to 77312th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 77312th to 77568th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 77568th to 77824th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 77824th to 78080th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 78080th to 78336th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 78336th to 78592th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 78592th to 78848th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 78848th to 79104th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 79104th to 79360th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 79360th to 79616th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 79616th to 79872th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 79872th to 80128th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 80128th to 80384th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 80384th to 80640th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 80640th to 80896th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 80896th to 81152th sample\n",
            "tokens obtained, start fitting model\n",
            "(256, 769)\n",
            "batch from 81152th to 81408th sample\n",
            "tokens obtained, start fitting model\n",
            "(54, 769)\n",
            "(81206, 769)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>759</th>\n",
              "      <th>760</th>\n",
              "      <th>761</th>\n",
              "      <th>762</th>\n",
              "      <th>763</th>\n",
              "      <th>764</th>\n",
              "      <th>765</th>\n",
              "      <th>766</th>\n",
              "      <th>767</th>\n",
              "      <th>768</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>25696644</td>\n",
              "      <td>-0.961882</td>\n",
              "      <td>-0.149763</td>\n",
              "      <td>-0.030739</td>\n",
              "      <td>-1.021122</td>\n",
              "      <td>0.191997</td>\n",
              "      <td>-0.305727</td>\n",
              "      <td>-0.699893</td>\n",
              "      <td>-0.370058</td>\n",
              "      <td>-0.260747</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.090940</td>\n",
              "      <td>0.739634</td>\n",
              "      <td>-0.700481</td>\n",
              "      <td>0.436043</td>\n",
              "      <td>1.198344</td>\n",
              "      <td>-0.129276</td>\n",
              "      <td>0.011377</td>\n",
              "      <td>0.181033</td>\n",
              "      <td>0.657025</td>\n",
              "      <td>-0.718310</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>26048429</td>\n",
              "      <td>-0.442894</td>\n",
              "      <td>-0.423292</td>\n",
              "      <td>-0.743249</td>\n",
              "      <td>-1.271860</td>\n",
              "      <td>0.189307</td>\n",
              "      <td>0.494722</td>\n",
              "      <td>-0.862139</td>\n",
              "      <td>-0.221709</td>\n",
              "      <td>-0.214980</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.699226</td>\n",
              "      <td>0.001578</td>\n",
              "      <td>0.051244</td>\n",
              "      <td>-0.160880</td>\n",
              "      <td>0.493710</td>\n",
              "      <td>0.014612</td>\n",
              "      <td>0.500069</td>\n",
              "      <td>0.564776</td>\n",
              "      <td>0.546543</td>\n",
              "      <td>-0.730617</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>26048429</td>\n",
              "      <td>-0.424305</td>\n",
              "      <td>-0.159977</td>\n",
              "      <td>-0.158158</td>\n",
              "      <td>-0.804049</td>\n",
              "      <td>-0.107067</td>\n",
              "      <td>0.969735</td>\n",
              "      <td>-1.070700</td>\n",
              "      <td>-0.028910</td>\n",
              "      <td>-0.361005</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.067264</td>\n",
              "      <td>0.025152</td>\n",
              "      <td>-0.046377</td>\n",
              "      <td>0.057703</td>\n",
              "      <td>0.960852</td>\n",
              "      <td>-0.091180</td>\n",
              "      <td>0.868535</td>\n",
              "      <td>-0.034059</td>\n",
              "      <td>1.105601</td>\n",
              "      <td>-0.274495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>20214994</td>\n",
              "      <td>-0.167130</td>\n",
              "      <td>-0.387770</td>\n",
              "      <td>-0.255653</td>\n",
              "      <td>-0.966652</td>\n",
              "      <td>-0.246591</td>\n",
              "      <td>0.796385</td>\n",
              "      <td>-0.892034</td>\n",
              "      <td>0.365918</td>\n",
              "      <td>-0.349409</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.563831</td>\n",
              "      <td>0.112659</td>\n",
              "      <td>-0.470008</td>\n",
              "      <td>0.359844</td>\n",
              "      <td>0.903242</td>\n",
              "      <td>-0.311563</td>\n",
              "      <td>0.605620</td>\n",
              "      <td>-0.036537</td>\n",
              "      <td>0.284726</td>\n",
              "      <td>-0.450746</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>20214994</td>\n",
              "      <td>-0.990296</td>\n",
              "      <td>0.236162</td>\n",
              "      <td>-0.891731</td>\n",
              "      <td>-0.060764</td>\n",
              "      <td>-0.043092</td>\n",
              "      <td>-0.045188</td>\n",
              "      <td>-1.281586</td>\n",
              "      <td>0.226228</td>\n",
              "      <td>0.261259</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.357992</td>\n",
              "      <td>0.056466</td>\n",
              "      <td>-0.378226</td>\n",
              "      <td>0.651119</td>\n",
              "      <td>0.847899</td>\n",
              "      <td>0.221708</td>\n",
              "      <td>0.307551</td>\n",
              "      <td>-0.120801</td>\n",
              "      <td>0.497500</td>\n",
              "      <td>-0.653763</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows  769 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        0         1         2         3         4         5         6    \\\n",
              "0  25696644 -0.961882 -0.149763 -0.030739 -1.021122  0.191997 -0.305727   \n",
              "1  26048429 -0.442894 -0.423292 -0.743249 -1.271860  0.189307  0.494722   \n",
              "2  26048429 -0.424305 -0.159977 -0.158158 -0.804049 -0.107067  0.969735   \n",
              "3  20214994 -0.167130 -0.387770 -0.255653 -0.966652 -0.246591  0.796385   \n",
              "4  20214994 -0.990296  0.236162 -0.891731 -0.060764 -0.043092 -0.045188   \n",
              "\n",
              "        7         8         9    ...       759       760       761       762  \\\n",
              "0 -0.699893 -0.370058 -0.260747  ... -0.090940  0.739634 -0.700481  0.436043   \n",
              "1 -0.862139 -0.221709 -0.214980  ... -0.699226  0.001578  0.051244 -0.160880   \n",
              "2 -1.070700 -0.028910 -0.361005  ... -0.067264  0.025152 -0.046377  0.057703   \n",
              "3 -0.892034  0.365918 -0.349409  ... -0.563831  0.112659 -0.470008  0.359844   \n",
              "4 -1.281586  0.226228  0.261259  ... -0.357992  0.056466 -0.378226  0.651119   \n",
              "\n",
              "        763       764       765       766       767       768  \n",
              "0  1.198344 -0.129276  0.011377  0.181033  0.657025 -0.718310  \n",
              "1  0.493710  0.014612  0.500069  0.564776  0.546543 -0.730617  \n",
              "2  0.960852 -0.091180  0.868535 -0.034059  1.105601 -0.274495  \n",
              "3  0.903242 -0.311563  0.605620 -0.036537  0.284726 -0.450746  \n",
              "4  0.847899  0.221708  0.307551 -0.120801  0.497500 -0.653763  \n",
              "\n",
              "[5 rows x 769 columns]"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# obtain embeddings\n",
        "res = embedding(notes, \"neuml/pubmedbert-base-embeddings\")\n",
        "print(res.shape)\n",
        "res.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "res.to_csv('pubmedbert_embedding.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Embedding aggregation\n",
        "1. average\n",
        "2. max pooling\n",
        "3. randomly select one"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(81206, 769)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>759</th>\n",
              "      <th>760</th>\n",
              "      <th>761</th>\n",
              "      <th>762</th>\n",
              "      <th>763</th>\n",
              "      <th>764</th>\n",
              "      <th>765</th>\n",
              "      <th>766</th>\n",
              "      <th>767</th>\n",
              "      <th>768</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>25696644</td>\n",
              "      <td>-0.961882</td>\n",
              "      <td>-0.149763</td>\n",
              "      <td>-0.030739</td>\n",
              "      <td>-1.021122</td>\n",
              "      <td>0.191997</td>\n",
              "      <td>-0.305727</td>\n",
              "      <td>-0.699893</td>\n",
              "      <td>-0.370058</td>\n",
              "      <td>-0.260747</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.090940</td>\n",
              "      <td>0.739634</td>\n",
              "      <td>-0.700481</td>\n",
              "      <td>0.436043</td>\n",
              "      <td>1.198344</td>\n",
              "      <td>-0.129276</td>\n",
              "      <td>0.011377</td>\n",
              "      <td>0.181033</td>\n",
              "      <td>0.657025</td>\n",
              "      <td>-0.718310</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>26048429</td>\n",
              "      <td>-0.442894</td>\n",
              "      <td>-0.423292</td>\n",
              "      <td>-0.743249</td>\n",
              "      <td>-1.271860</td>\n",
              "      <td>0.189307</td>\n",
              "      <td>0.494722</td>\n",
              "      <td>-0.862139</td>\n",
              "      <td>-0.221709</td>\n",
              "      <td>-0.214980</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.699226</td>\n",
              "      <td>0.001578</td>\n",
              "      <td>0.051244</td>\n",
              "      <td>-0.160880</td>\n",
              "      <td>0.493710</td>\n",
              "      <td>0.014612</td>\n",
              "      <td>0.500069</td>\n",
              "      <td>0.564776</td>\n",
              "      <td>0.546543</td>\n",
              "      <td>-0.730617</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>26048429</td>\n",
              "      <td>-0.424305</td>\n",
              "      <td>-0.159977</td>\n",
              "      <td>-0.158158</td>\n",
              "      <td>-0.804049</td>\n",
              "      <td>-0.107067</td>\n",
              "      <td>0.969735</td>\n",
              "      <td>-1.070700</td>\n",
              "      <td>-0.028910</td>\n",
              "      <td>-0.361005</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.067264</td>\n",
              "      <td>0.025152</td>\n",
              "      <td>-0.046377</td>\n",
              "      <td>0.057703</td>\n",
              "      <td>0.960852</td>\n",
              "      <td>-0.091180</td>\n",
              "      <td>0.868535</td>\n",
              "      <td>-0.034059</td>\n",
              "      <td>1.105601</td>\n",
              "      <td>-0.274495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>20214994</td>\n",
              "      <td>-0.167130</td>\n",
              "      <td>-0.387770</td>\n",
              "      <td>-0.255653</td>\n",
              "      <td>-0.966652</td>\n",
              "      <td>-0.246591</td>\n",
              "      <td>0.796385</td>\n",
              "      <td>-0.892034</td>\n",
              "      <td>0.365918</td>\n",
              "      <td>-0.349409</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.563831</td>\n",
              "      <td>0.112659</td>\n",
              "      <td>-0.470008</td>\n",
              "      <td>0.359844</td>\n",
              "      <td>0.903242</td>\n",
              "      <td>-0.311563</td>\n",
              "      <td>0.605620</td>\n",
              "      <td>-0.036537</td>\n",
              "      <td>0.284726</td>\n",
              "      <td>-0.450746</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>20214994</td>\n",
              "      <td>-0.990296</td>\n",
              "      <td>0.236162</td>\n",
              "      <td>-0.891731</td>\n",
              "      <td>-0.060764</td>\n",
              "      <td>-0.043092</td>\n",
              "      <td>-0.045188</td>\n",
              "      <td>-1.281586</td>\n",
              "      <td>0.226228</td>\n",
              "      <td>0.261259</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.357992</td>\n",
              "      <td>0.056466</td>\n",
              "      <td>-0.378226</td>\n",
              "      <td>0.651119</td>\n",
              "      <td>0.847899</td>\n",
              "      <td>0.221708</td>\n",
              "      <td>0.307551</td>\n",
              "      <td>-0.120801</td>\n",
              "      <td>0.497500</td>\n",
              "      <td>-0.653763</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows  769 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         id         1         2         3         4         5         6  \\\n",
              "0  25696644 -0.961882 -0.149763 -0.030739 -1.021122  0.191997 -0.305727   \n",
              "1  26048429 -0.442894 -0.423292 -0.743249 -1.271860  0.189307  0.494722   \n",
              "2  26048429 -0.424305 -0.159977 -0.158158 -0.804049 -0.107067  0.969735   \n",
              "3  20214994 -0.167130 -0.387770 -0.255653 -0.966652 -0.246591  0.796385   \n",
              "4  20214994 -0.990296  0.236162 -0.891731 -0.060764 -0.043092 -0.045188   \n",
              "\n",
              "          7         8         9  ...       759       760       761       762  \\\n",
              "0 -0.699893 -0.370058 -0.260747  ... -0.090940  0.739634 -0.700481  0.436043   \n",
              "1 -0.862139 -0.221709 -0.214980  ... -0.699226  0.001578  0.051244 -0.160880   \n",
              "2 -1.070700 -0.028910 -0.361005  ... -0.067264  0.025152 -0.046377  0.057703   \n",
              "3 -0.892034  0.365918 -0.349409  ... -0.563831  0.112659 -0.470008  0.359844   \n",
              "4 -1.281586  0.226228  0.261259  ... -0.357992  0.056466 -0.378226  0.651119   \n",
              "\n",
              "        763       764       765       766       767       768  \n",
              "0  1.198344 -0.129276  0.011377  0.181033  0.657025 -0.718310  \n",
              "1  0.493710  0.014612  0.500069  0.564776  0.546543 -0.730617  \n",
              "2  0.960852 -0.091180  0.868535 -0.034059  1.105601 -0.274495  \n",
              "3  0.903242 -0.311563  0.605620 -0.036537  0.284726 -0.450746  \n",
              "4  0.847899  0.221708  0.307551 -0.120801  0.497500 -0.653763  \n",
              "\n",
              "[5 rows x 769 columns]"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "embedding = pd.read_csv(\"./pubmedbert_embedding.csv\")\n",
        "embedding.rename(columns={'0': 'id'}, inplace=True)\n",
        "print(embedding.shape)\n",
        "embedding.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_549761/306674092.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  test.rename(columns={'0': 'id'}, inplace=True)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>759</th>\n",
              "      <th>760</th>\n",
              "      <th>761</th>\n",
              "      <th>762</th>\n",
              "      <th>763</th>\n",
              "      <th>764</th>\n",
              "      <th>765</th>\n",
              "      <th>766</th>\n",
              "      <th>767</th>\n",
              "      <th>768</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>20000</th>\n",
              "      <td>26870909</td>\n",
              "      <td>-0.538786</td>\n",
              "      <td>-0.033661</td>\n",
              "      <td>0.628227</td>\n",
              "      <td>-0.562071</td>\n",
              "      <td>-0.133268</td>\n",
              "      <td>-0.058549</td>\n",
              "      <td>-0.707114</td>\n",
              "      <td>0.423699</td>\n",
              "      <td>-0.775430</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.355354</td>\n",
              "      <td>-0.520007</td>\n",
              "      <td>-0.145064</td>\n",
              "      <td>0.749140</td>\n",
              "      <td>0.420206</td>\n",
              "      <td>-0.729575</td>\n",
              "      <td>0.048278</td>\n",
              "      <td>-0.297783</td>\n",
              "      <td>0.272952</td>\n",
              "      <td>-0.711024</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20001</th>\n",
              "      <td>27727321</td>\n",
              "      <td>-0.490337</td>\n",
              "      <td>0.126018</td>\n",
              "      <td>-0.787498</td>\n",
              "      <td>-0.433758</td>\n",
              "      <td>-0.107921</td>\n",
              "      <td>1.119397</td>\n",
              "      <td>-1.464724</td>\n",
              "      <td>-0.043529</td>\n",
              "      <td>-0.234906</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.618939</td>\n",
              "      <td>-0.069264</td>\n",
              "      <td>-0.147243</td>\n",
              "      <td>0.215716</td>\n",
              "      <td>0.701113</td>\n",
              "      <td>-0.217276</td>\n",
              "      <td>0.324226</td>\n",
              "      <td>-0.045105</td>\n",
              "      <td>0.367587</td>\n",
              "      <td>-0.679906</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20002</th>\n",
              "      <td>27727321</td>\n",
              "      <td>-0.776378</td>\n",
              "      <td>0.614439</td>\n",
              "      <td>0.076600</td>\n",
              "      <td>-0.121490</td>\n",
              "      <td>0.141488</td>\n",
              "      <td>-0.167427</td>\n",
              "      <td>-0.827510</td>\n",
              "      <td>0.726984</td>\n",
              "      <td>0.006872</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.208094</td>\n",
              "      <td>0.372850</td>\n",
              "      <td>-0.380829</td>\n",
              "      <td>1.214288</td>\n",
              "      <td>0.292794</td>\n",
              "      <td>-0.963728</td>\n",
              "      <td>0.137193</td>\n",
              "      <td>-0.589385</td>\n",
              "      <td>0.067548</td>\n",
              "      <td>-1.599590</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20003</th>\n",
              "      <td>27727321</td>\n",
              "      <td>-0.296081</td>\n",
              "      <td>0.250667</td>\n",
              "      <td>-0.121046</td>\n",
              "      <td>-0.068658</td>\n",
              "      <td>0.268956</td>\n",
              "      <td>0.670307</td>\n",
              "      <td>-0.822947</td>\n",
              "      <td>0.570372</td>\n",
              "      <td>0.135268</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.544799</td>\n",
              "      <td>-0.744366</td>\n",
              "      <td>-0.346079</td>\n",
              "      <td>0.679209</td>\n",
              "      <td>0.245669</td>\n",
              "      <td>-0.741133</td>\n",
              "      <td>0.526469</td>\n",
              "      <td>0.254001</td>\n",
              "      <td>-0.079056</td>\n",
              "      <td>-0.542372</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20004</th>\n",
              "      <td>29510747</td>\n",
              "      <td>-0.234447</td>\n",
              "      <td>-0.176070</td>\n",
              "      <td>-0.092110</td>\n",
              "      <td>-0.787402</td>\n",
              "      <td>0.355860</td>\n",
              "      <td>0.713764</td>\n",
              "      <td>-1.375800</td>\n",
              "      <td>-0.408523</td>\n",
              "      <td>-0.443587</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.744142</td>\n",
              "      <td>-0.172968</td>\n",
              "      <td>-0.075356</td>\n",
              "      <td>-0.088719</td>\n",
              "      <td>1.486721</td>\n",
              "      <td>-0.237053</td>\n",
              "      <td>0.435958</td>\n",
              "      <td>0.075690</td>\n",
              "      <td>0.888237</td>\n",
              "      <td>0.037683</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows  769 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "             id         1         2         3         4         5         6  \\\n",
              "20000  26870909 -0.538786 -0.033661  0.628227 -0.562071 -0.133268 -0.058549   \n",
              "20001  27727321 -0.490337  0.126018 -0.787498 -0.433758 -0.107921  1.119397   \n",
              "20002  27727321 -0.776378  0.614439  0.076600 -0.121490  0.141488 -0.167427   \n",
              "20003  27727321 -0.296081  0.250667 -0.121046 -0.068658  0.268956  0.670307   \n",
              "20004  29510747 -0.234447 -0.176070 -0.092110 -0.787402  0.355860  0.713764   \n",
              "\n",
              "              7         8         9  ...       759       760       761  \\\n",
              "20000 -0.707114  0.423699 -0.775430  ... -0.355354 -0.520007 -0.145064   \n",
              "20001 -1.464724 -0.043529 -0.234906  ... -0.618939 -0.069264 -0.147243   \n",
              "20002 -0.827510  0.726984  0.006872  ... -0.208094  0.372850 -0.380829   \n",
              "20003 -0.822947  0.570372  0.135268  ... -0.544799 -0.744366 -0.346079   \n",
              "20004 -1.375800 -0.408523 -0.443587  ... -0.744142 -0.172968 -0.075356   \n",
              "\n",
              "            762       763       764       765       766       767       768  \n",
              "20000  0.749140  0.420206 -0.729575  0.048278 -0.297783  0.272952 -0.711024  \n",
              "20001  0.215716  0.701113 -0.217276  0.324226 -0.045105  0.367587 -0.679906  \n",
              "20002  1.214288  0.292794 -0.963728  0.137193 -0.589385  0.067548 -1.599590  \n",
              "20003  0.679209  0.245669 -0.741133  0.526469  0.254001 -0.079056 -0.542372  \n",
              "20004 -0.088719  1.486721 -0.237053  0.435958  0.075690  0.888237  0.037683  \n",
              "\n",
              "[5 rows x 769 columns]"
            ]
          },
          "execution_count": 122,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test = embedding[20000:22000]\n",
        "test.rename(columns={'0': 'id'}, inplace=True)\n",
        "test.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>759</th>\n",
              "      <th>760</th>\n",
              "      <th>761</th>\n",
              "      <th>762</th>\n",
              "      <th>763</th>\n",
              "      <th>764</th>\n",
              "      <th>765</th>\n",
              "      <th>766</th>\n",
              "      <th>767</th>\n",
              "      <th>768</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>20214994.0</td>\n",
              "      <td>-0.990296</td>\n",
              "      <td>0.236162</td>\n",
              "      <td>-0.891731</td>\n",
              "      <td>-0.060764</td>\n",
              "      <td>-0.043092</td>\n",
              "      <td>-0.045188</td>\n",
              "      <td>-1.281586</td>\n",
              "      <td>0.226228</td>\n",
              "      <td>0.261259</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.357992</td>\n",
              "      <td>0.056466</td>\n",
              "      <td>-0.378226</td>\n",
              "      <td>0.651119</td>\n",
              "      <td>0.847899</td>\n",
              "      <td>0.221708</td>\n",
              "      <td>0.307551</td>\n",
              "      <td>-0.120801</td>\n",
              "      <td>0.4975</td>\n",
              "      <td>-0.653763</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1 rows  769 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           id         1         2         3         4         5         6  \\\n",
              "4  20214994.0 -0.990296  0.236162 -0.891731 -0.060764 -0.043092 -0.045188   \n",
              "\n",
              "          7         8         9  ...       759       760       761       762  \\\n",
              "4 -1.281586  0.226228  0.261259  ... -0.357992  0.056466 -0.378226  0.651119   \n",
              "\n",
              "        763       764       765       766     767       768  \n",
              "4  0.847899  0.221708  0.307551 -0.120801  0.4975 -0.653763  \n",
              "\n",
              "[1 rows x 769 columns]"
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pd.DataFrame(test[test['id']==20214994].iloc[1]).T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([25696644, 26048429, 20214994, 23559586, 24181354, 28128182,\n",
              "       29988601, 22869003, 27939719, 23920883, 26488315, 25777141,\n",
              "       22081550, 22987108, 22218665, 20291550, 23676183, 26359957,\n",
              "       29842315, 22429197, 22216667])"
            ]
          },
          "execution_count": 55,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pd.unique(test['id'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 128,
      "metadata": {},
      "outputs": [],
      "source": [
        "def avg(df):\n",
        "    res = df.groupby('id').mean().reset_index()\n",
        "    return res\n",
        "\n",
        "def max_pooling(df):\n",
        "    res = df.groupby('id').max().reset_index()\n",
        "    return res\n",
        "\n",
        "def return_random_note(rows, rand_n):\n",
        "    # rows = df[df['id']==id]\n",
        "    # print(rows.shape, rand_n)\n",
        "    res = pd.DataFrame(rows.iloc[rand_n]).T\n",
        "    return res\n",
        "\n",
        "def random_sample(df):\n",
        "    # obtain count of notes for each id\n",
        "    N = df.groupby('id').size().to_frame().reset_index()\n",
        "    N.rename(columns={0: 'count'}, inplace=True)\n",
        "\n",
        "    # generate a random number for each id\n",
        "    N['rand'] = N.apply(lambda x: np.random.randint(0, x['count']), axis=1)\n",
        "\n",
        "    # obtain random note for each id\n",
        "    res = pd.DataFrame()\n",
        "    count = 0\n",
        "    id_ls = pd.unique(df['id'])\n",
        "    res_ls = []\n",
        "    for id in id_ls:\n",
        "        rand_n = N[N['id']==id]['rand'].iloc[0]\n",
        "        rows = df[df['id']==id]\n",
        "        selected = return_random_note(rows, rand_n)\n",
        "        # res = pd.concat([res, selected], ignore_index=True)\n",
        "        res_ls.append(selected)\n",
        "\n",
        "        count += 1\n",
        "        if count % 500 == 0:\n",
        "            print(f\"{count} unique ids finished\")\n",
        "\n",
        "    res = pd.concat(res_ls)\n",
        "    return res"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(20414, 769)\n"
          ]
        }
      ],
      "source": [
        "pubmed_avg = avg(embedding)\n",
        "print(pubmed_avg.shape)\n",
        "# pubmed_avg.to_csv(\"pubmed_avg.csv\", index=False)# "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(20414, 769)\n"
          ]
        }
      ],
      "source": [
        "pubmed_max = max_pooling(embedding)\n",
        "print(pubmed_max.shape)\n",
        "# pubmed_max.to_csv(\"pubmed_max.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {},
      "outputs": [],
      "source": [
        "del pubmed_avg\n",
        "del pubmed_max"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(20414,)"
            ]
          },
          "execution_count": 110,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pd.unique(embedding['id']).shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['id', '1', '2', '3', '4', '5', '6', '7', '8', '9',\n",
              "       ...\n",
              "       '759', '760', '761', '762', '763', '764', '765', '766', '767', '768'],\n",
              "      dtype='object', length=769)"
            ]
          },
          "execution_count": 115,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "embedding.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 130,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "500 unique ids finished\n",
            "1000 unique ids finished\n",
            "1500 unique ids finished\n",
            "2000 unique ids finished\n",
            "2500 unique ids finished\n",
            "3000 unique ids finished\n",
            "3500 unique ids finished\n",
            "4000 unique ids finished\n",
            "4500 unique ids finished\n",
            "5000 unique ids finished\n",
            "5500 unique ids finished\n",
            "6000 unique ids finished\n",
            "6500 unique ids finished\n",
            "7000 unique ids finished\n",
            "7500 unique ids finished\n",
            "8000 unique ids finished\n",
            "8500 unique ids finished\n",
            "9000 unique ids finished\n",
            "9500 unique ids finished\n",
            "10000 unique ids finished\n",
            "10500 unique ids finished\n",
            "11000 unique ids finished\n",
            "11500 unique ids finished\n",
            "12000 unique ids finished\n",
            "12500 unique ids finished\n",
            "13000 unique ids finished\n",
            "13500 unique ids finished\n",
            "14000 unique ids finished\n",
            "14500 unique ids finished\n",
            "15000 unique ids finished\n",
            "15500 unique ids finished\n",
            "16000 unique ids finished\n",
            "16500 unique ids finished\n",
            "17000 unique ids finished\n",
            "17500 unique ids finished\n",
            "18000 unique ids finished\n",
            "18500 unique ids finished\n",
            "19000 unique ids finished\n",
            "19500 unique ids finished\n",
            "20000 unique ids finished\n",
            "(20414, 769)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>759</th>\n",
              "      <th>760</th>\n",
              "      <th>761</th>\n",
              "      <th>762</th>\n",
              "      <th>763</th>\n",
              "      <th>764</th>\n",
              "      <th>765</th>\n",
              "      <th>766</th>\n",
              "      <th>767</th>\n",
              "      <th>768</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>25696644.0</td>\n",
              "      <td>-0.961882</td>\n",
              "      <td>-0.149763</td>\n",
              "      <td>-0.030739</td>\n",
              "      <td>-1.021122</td>\n",
              "      <td>0.191997</td>\n",
              "      <td>-0.305727</td>\n",
              "      <td>-0.699893</td>\n",
              "      <td>-0.370058</td>\n",
              "      <td>-0.260747</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.090940</td>\n",
              "      <td>0.739634</td>\n",
              "      <td>-0.700481</td>\n",
              "      <td>0.436043</td>\n",
              "      <td>1.198344</td>\n",
              "      <td>-0.129276</td>\n",
              "      <td>0.011377</td>\n",
              "      <td>0.181033</td>\n",
              "      <td>0.657025</td>\n",
              "      <td>-0.718310</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>26048429.0</td>\n",
              "      <td>-0.424305</td>\n",
              "      <td>-0.159977</td>\n",
              "      <td>-0.158158</td>\n",
              "      <td>-0.804049</td>\n",
              "      <td>-0.107067</td>\n",
              "      <td>0.969735</td>\n",
              "      <td>-1.070700</td>\n",
              "      <td>-0.028910</td>\n",
              "      <td>-0.361005</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.067264</td>\n",
              "      <td>0.025152</td>\n",
              "      <td>-0.046377</td>\n",
              "      <td>0.057703</td>\n",
              "      <td>0.960852</td>\n",
              "      <td>-0.091180</td>\n",
              "      <td>0.868535</td>\n",
              "      <td>-0.034059</td>\n",
              "      <td>1.105601</td>\n",
              "      <td>-0.274495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>20214994.0</td>\n",
              "      <td>-0.447072</td>\n",
              "      <td>-0.479759</td>\n",
              "      <td>-0.389428</td>\n",
              "      <td>-0.755359</td>\n",
              "      <td>0.238575</td>\n",
              "      <td>1.226583</td>\n",
              "      <td>-1.005992</td>\n",
              "      <td>-0.461748</td>\n",
              "      <td>0.192283</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.264748</td>\n",
              "      <td>0.254763</td>\n",
              "      <td>-0.156440</td>\n",
              "      <td>-0.025247</td>\n",
              "      <td>1.146273</td>\n",
              "      <td>-0.286280</td>\n",
              "      <td>0.136631</td>\n",
              "      <td>-0.222716</td>\n",
              "      <td>0.371108</td>\n",
              "      <td>-0.076180</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>23559586.0</td>\n",
              "      <td>-0.736017</td>\n",
              "      <td>0.230110</td>\n",
              "      <td>1.104697</td>\n",
              "      <td>-0.541268</td>\n",
              "      <td>-0.361138</td>\n",
              "      <td>-0.356820</td>\n",
              "      <td>-1.131791</td>\n",
              "      <td>0.329295</td>\n",
              "      <td>-0.190179</td>\n",
              "      <td>...</td>\n",
              "      <td>0.157699</td>\n",
              "      <td>-0.016856</td>\n",
              "      <td>-0.400899</td>\n",
              "      <td>0.286962</td>\n",
              "      <td>0.302196</td>\n",
              "      <td>-0.449930</td>\n",
              "      <td>0.583222</td>\n",
              "      <td>-0.040345</td>\n",
              "      <td>0.822514</td>\n",
              "      <td>-0.462158</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>24181354.0</td>\n",
              "      <td>-0.927706</td>\n",
              "      <td>0.178118</td>\n",
              "      <td>0.555045</td>\n",
              "      <td>-1.186871</td>\n",
              "      <td>-0.107297</td>\n",
              "      <td>-0.137812</td>\n",
              "      <td>-0.570643</td>\n",
              "      <td>-0.497850</td>\n",
              "      <td>-0.534740</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.210950</td>\n",
              "      <td>0.260646</td>\n",
              "      <td>-0.443489</td>\n",
              "      <td>0.493528</td>\n",
              "      <td>0.777205</td>\n",
              "      <td>-0.347572</td>\n",
              "      <td>0.594686</td>\n",
              "      <td>-0.174461</td>\n",
              "      <td>0.775348</td>\n",
              "      <td>-0.330190</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows  769 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            id         1         2         3         4         5         6  \\\n",
              "0   25696644.0 -0.961882 -0.149763 -0.030739 -1.021122  0.191997 -0.305727   \n",
              "2   26048429.0 -0.424305 -0.159977 -0.158158 -0.804049 -0.107067  0.969735   \n",
              "5   20214994.0 -0.447072 -0.479759 -0.389428 -0.755359  0.238575  1.226583   \n",
              "10  23559586.0 -0.736017  0.230110  1.104697 -0.541268 -0.361138 -0.356820   \n",
              "17  24181354.0 -0.927706  0.178118  0.555045 -1.186871 -0.107297 -0.137812   \n",
              "\n",
              "           7         8         9  ...       759       760       761       762  \\\n",
              "0  -0.699893 -0.370058 -0.260747  ... -0.090940  0.739634 -0.700481  0.436043   \n",
              "2  -1.070700 -0.028910 -0.361005  ... -0.067264  0.025152 -0.046377  0.057703   \n",
              "5  -1.005992 -0.461748  0.192283  ... -0.264748  0.254763 -0.156440 -0.025247   \n",
              "10 -1.131791  0.329295 -0.190179  ...  0.157699 -0.016856 -0.400899  0.286962   \n",
              "17 -0.570643 -0.497850 -0.534740  ... -0.210950  0.260646 -0.443489  0.493528   \n",
              "\n",
              "         763       764       765       766       767       768  \n",
              "0   1.198344 -0.129276  0.011377  0.181033  0.657025 -0.718310  \n",
              "2   0.960852 -0.091180  0.868535 -0.034059  1.105601 -0.274495  \n",
              "5   1.146273 -0.286280  0.136631 -0.222716  0.371108 -0.076180  \n",
              "10  0.302196 -0.449930  0.583222 -0.040345  0.822514 -0.462158  \n",
              "17  0.777205 -0.347572  0.594686 -0.174461  0.775348 -0.330190  \n",
              "\n",
              "[5 rows x 769 columns]"
            ]
          },
          "execution_count": 130,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pubmed_rand = random_sample(embedding)\n",
        "print(pubmed_rand.shape)\n",
        "pubmed_rand.head()\n",
        "# pubmed_rand.to_csv(\"pubmed_rand.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 131,
      "metadata": {},
      "outputs": [],
      "source": [
        "pubmed_rand.to_csv(\"pubmed_rand.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "09ce4c5e822445098eb77414b27a437c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_728681d36d404e4ea79c0410f7831f4d",
            "placeholder": "",
            "style": "IPY_MODEL_4b78b62a760045e597417f9f0559b8ad",
            "value": "config.json:100%"
          }
        },
        "2a4ab2707b264a21b7796e4e28bcb1e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f187031af28543359c9f514a4e6b999b",
            "placeholder": "",
            "style": "IPY_MODEL_5b0f8197398f411c88643e2476ad504d",
            "value": "438M/438M[00:01&lt;00:00,291MB/s]"
          }
        },
        "2c02f0c35f144c369ae20fbd5760efc4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f52d6876a46a4cc1b212cf04928581ba",
            "placeholder": "",
            "style": "IPY_MODEL_d8710dbf87824f9c9a5488de9c468879",
            "value": "pytorch_model.bin:100%"
          }
        },
        "2f0be7dc36734becb862adc8c698d4a8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "322f68c193d64c3f92cb352ccdd73278": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "40dd26682bd44b9d8de3600829967513": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2c02f0c35f144c369ae20fbd5760efc4",
              "IPY_MODEL_88780721d2d24779aced35c045e4fc28",
              "IPY_MODEL_2a4ab2707b264a21b7796e4e28bcb1e4"
            ],
            "layout": "IPY_MODEL_5ecd8a83fc4b48fd8290fe60ec5815b9"
          }
        },
        "4b78b62a760045e597417f9f0559b8ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "512d5b4784e1448bbd51542a5ac76533": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_09ce4c5e822445098eb77414b27a437c",
              "IPY_MODEL_c7dee6020f174d7eb9b308e75de8430e",
              "IPY_MODEL_ffb540dfc46b4503b9a1bf06368fffa6"
            ],
            "layout": "IPY_MODEL_2f0be7dc36734becb862adc8c698d4a8"
          }
        },
        "56f710846b8d4351b4f598afea5ebc0b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5b0f8197398f411c88643e2476ad504d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5ecd8a83fc4b48fd8290fe60ec5815b9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "728681d36d404e4ea79c0410f7831f4d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "823c739b4a2a482a9515b6a4b90683bd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "88780721d2d24779aced35c045e4fc28": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_823c739b4a2a482a9515b6a4b90683bd",
            "max": 437995689,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8f9347d60d1b45b0b9614f27d18d3214",
            "value": 437995689
          }
        },
        "8f9347d60d1b45b0b9614f27d18d3214": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a847a16f3085463d8000b97e451a59bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c7dee6020f174d7eb9b308e75de8430e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_56f710846b8d4351b4f598afea5ebc0b",
            "max": 667,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a847a16f3085463d8000b97e451a59bc",
            "value": 667
          }
        },
        "d8710dbf87824f9c9a5488de9c468879": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e93c20dfceec45fc9be4723b673e2b64": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f187031af28543359c9f514a4e6b999b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f52d6876a46a4cc1b212cf04928581ba": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ffb540dfc46b4503b9a1bf06368fffa6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e93c20dfceec45fc9be4723b673e2b64",
            "placeholder": "",
            "style": "IPY_MODEL_322f68c193d64c3f92cb352ccdd73278",
            "value": "667/667[00:00&lt;00:00,8.83kB/s]"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
